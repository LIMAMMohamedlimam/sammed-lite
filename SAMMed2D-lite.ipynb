{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c383648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/limam/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad31701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "\n",
    "# filelist=(\"sam_vit_b_01ec64.pth\" \"sample_data\")\n",
    "\n",
    "# pat=$(printf \"^%s$\" \"${filelist[@]}\")\n",
    "# pat=${pat:1}\n",
    "\n",
    "\n",
    "# ls | grep -Ev \"$pat\" | xargs rm -rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1ea8fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t       LitePredictor.py     SAMMed2DLite.py   train.py\n",
      "DataLoader.py  SAMMed2D-lite.ipynb  segment_anything  utils.py\n"
     ]
    }
   ],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13411f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: copied repo content into ./\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'temp_repo'...\n"
     ]
    }
   ],
   "source": [
    "# %%bash\n",
    "\n",
    "# # Variables\n",
    "# REPO_URL=\"https://github.com/LIMAMMohamedlimam/sammed-lite.git\"\n",
    "# CLONE_DIR=\"temp_repo\"\n",
    "# TARGET_DIR=\"./\"\n",
    "# git clone \"$REPO_URL\" \"$CLONE_DIR\"\n",
    "\n",
    "# # Create target directory if it doesn't exist\n",
    "# mkdir -p \"$TARGET_DIR\"\n",
    "\n",
    "# # Copy all contents (including hidden files)\n",
    "# cp -r \"$CLONE_DIR\"/. \"$TARGET_DIR\"/\n",
    "\n",
    "# # Delete cloned repo directory\n",
    "# rm -rf \"$CLONE_DIR\"\n",
    "\n",
    "# echo \"Done: copied repo content into $TARGET_DIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13ef5c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t       LitePredictor.py     SAMMed2DLite.py   train.py\n",
      "DataLoader.py  SAMMed2D-lite.ipynb  segment_anything  utils.py\n"
     ]
    }
   ],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c84aa32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f5d4aa",
   "metadata": {},
   "source": [
    "## Loading SAM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ceaed22",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mSAMMed2DLite\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SAMMed2DLite\n",
      "File \u001b[0;32m~/Desktop/Sam-Med2D-Lite/SAMMed2DLite.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msegment_anything\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sam\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mSAMMed2DLite\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n",
      "File \u001b[0;32m~/Desktop/Sam-Med2D-Lite/segment_anything/__init__.py:14\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Meta Platforms, Inc. and affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# All rights reserved.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the license found in the\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuild_sam\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     build_sam,\n\u001b[1;32m      9\u001b[0m     build_sam_vit_h,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     sam_model_registry,\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredictor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SamPredictor\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautomatic_mask_generator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SamAutomaticMaskGenerator\n",
      "File \u001b[0;32m~/Desktop/Sam-Med2D-Lite/segment_anything/predictor.py:14\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msegment_anything\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sam\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optional, Tuple\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ResizeLongestSide\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mSamPredictor\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     20\u001b[0m         sam_model: Sam,\n\u001b[1;32m     21\u001b[0m     ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/Sam-Med2D-Lite/segment_anything/utils/transforms.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m resize, to_pil_image  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcopy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deepcopy\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tuple\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "from SAMMed2DLite import SAMMed2DLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e603d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadf54b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything import sam_model_registry\n",
    "\n",
    "sam_checkpoint = \"sam_vit_b_01ec64.pth\"\n",
    "model_type = \"vit_b\"\n",
    "\n",
    "# Load base SAM\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cccf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAMMed2DLite(sam_model=sam).to(device)\n",
    "print(f\"Model loaded with {sum(p.numel() for p in model.parameters() if p.requires_grad):,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dfc13c",
   "metadata": {},
   "source": [
    "## Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42731464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataLoader import DatasetLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c9a0ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using num_workers = 2\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def get_num_workers():\n",
    "    cpu_count = multiprocessing.cpu_count()\n",
    "    has_gpu = torch.cuda.is_available()\n",
    "    if has_gpu:\n",
    "        return min(2, cpu_count)\n",
    "    else:\n",
    "        return min(2, cpu_count)\n",
    "\n",
    "num_workers = get_num_workers()\n",
    "\n",
    "print(\"Using num_workers =\", num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5140e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training dataset loaded!\n",
      "testing dataset loaded!\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"data_demo\"\n",
    "train_dataset = DatasetLoader(data_dir=data_dir)\n",
    "test_dataset = DatasetLoader(data_dir=data_dir , mode=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880b418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0b3c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train_model\n",
    "#Train\n",
    "\n",
    "history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    num_epochs=50,\n",
    "    learning_rate=1e-4,\n",
    "    save_dir='checkpoints',\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3bd9b4",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cb93e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import evaluate_batch\n",
    "# Load best checkpoint\n",
    "checkpoint = torch.load('checkpoints/best_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Evaluate on test set\n",
    "test_dataset = DatasetLoader(\n",
    "    image_dir='data/test/images',\n",
    "    mask_dir='data/test/masks',\n",
    "    image_size=256,\n",
    "    train=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Run evaluation\n",
    "test_metrics = evaluate_batch(model, test_loader, device)\n",
    "\n",
    "print(\"\\n=== Test Results ===\")\n",
    "print(f\"Dice Coefficient: {test_metrics['dice']:.4f}\")\n",
    "print(f\"IoU: {test_metrics['iou']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ec4a06",
   "metadata": {},
   "source": [
    "## training history plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a19f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_training_history(history, save_path='training_curves.png'):\n",
    "    \"\"\"Visualize training progress\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Loss curve\n",
    "    axes[0].plot(history['train_loss'], label='Train Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Training Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Metrics curves\n",
    "    axes[1].plot(history['val_dice'], label='Dice', marker='o')\n",
    "    axes[1].plot(history['val_iou'], label='IoU', marker='s')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Score')\n",
    "    axes[1].set_title('Validation Metrics')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278d650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history=history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
